## Config file

# Log 
seed: 777
use_cuda: 1           # 1 for True, 0 for False

# dataset
speaker_no: 2
mix_lst_path: ./data/LRS3/mixture_data_list_2mix.csv
audio_direc: /mnt/nas_sg/wulanchabu/zexu.pan/datasets/LRS3/audio_clean/
reference_direc: /mnt/nas_sg/wulanchabu/zexu.pan/datasets/LRS3/orig/
audio_sr: 16000
ref_sr: 25

# dataloader
num_workers: 4
batch_size: 4         # 4-GPU training with a total effective batch size of 16
accu_grad: 0
effec_batch_size: 4   # per GPU, only used if accu_grad is set to 1, must be multiple times of batch size
max_length: 6         # truncate the utterances in dataloader, in seconds 

# network settings
init_from: None       # 'None' or a log name 'log_2024-07-22(18:12:13)'
causal: 1             # 1 for True, 0 for False
network_reference:
  cue: lip            # lip or speech or gesture or EEG
  backbone: blazenet64  # blazenet64
network_audio:
  backbone: av_skim
  window: 16
  input_dim: 128
  layer: 3
  unit: 384
  segment_size: 50

  image_size: 128    # 128 for blazenet64
  img_emb_size: 224  # front model 320, back model 224, baseline 512

  tcn_attractor: 0

# optimizer
loss_type: sisdr      # "snr", "sisdr", "hybrid"
init_learning_rate: 0.001
max_epoch: 150
clip_grad_norm: 5
